# -*- coding: utf-8 -*-
"""
Monthly_pipeline_3.py
–ü–æ–ª–Ω–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã + –¥–∞—à–±–æ—Ä–¥ + –≤—ã–≥—Ä—É–∑–∫–∞ –≤ Excel.
"""

import io
from dataclasses import dataclass, field
from typing import Dict, Tuple, Optional, List

import streamlit as st
import pandas as pd
import numpy as np

# ---------- Optional deps ----------
try:
    import altair as alt
    ALTAIR_OK = True
except Exception:
    ALTAIR_OK = False

SKLEARN_OK, SKLEARN_ERR = True, ""
try:
    from sklearn.pipeline import Pipeline as SkPipeline
    from sklearn.linear_model import LogisticRegression
    from sklearn.feature_extraction.text import TfidfVectorizer
except Exception as e:
    SKLEARN_OK, SKLEARN_ERR = False, str(e)

# ---------- Page ----------
st.set_page_config(page_title="Monthly Pipeline 3 ‚Äî Artel", layout="wide")
st.title("–§–∏–Ω–∞–Ω—Å–æ–≤—ã–π –ø–∞–π–ø–ª–∞–π–Ω (Monthly pipeline 3)")
st.caption("–§–∏–ª—å—Ç—Ä—ã ‚Üí —Å–≤–æ–¥—ã ‚Üí –¥–∞—à–±–æ—Ä–¥ ‚Üí Excel")

MONEY_FORMAT_RU = '# ##0,00'
EXCLUDE_NUM_FMT = {"ticket_id","–ù–æ–º–µ—Ä –∑–∞—è–≤–∫–∏","service_code","–ö–æ–¥ —É—Å–ª—É–≥–∏","product_code","–ö–æ–¥ –ø—Ä–æ–¥—É–∫—Ç–∞"}

# ---------- Helpers ----------
def coalesce_duplicate_columns(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    counts = out.columns.value_counts()
    for name in counts[counts > 1].index:
        cols = [c for c in out.columns if c == name]
        out[name] = out[cols].bfill(axis=1).iloc[:, 0]
        for c in cols[1:]:
            out.drop(columns=c, inplace=True)
    return out

def ensure_ticket_id_text_inplace(df: pd.DataFrame) -> None:
    if "ticket_id" in df.columns:
        df["ticket_id"] = pd.to_numeric(df["ticket_id"], errors="coerce") \
            .apply(lambda v: "" if pd.isna(v) else str(int(v)))

def existing_cols(df: pd.DataFrame, cols: List[str]) -> List[str]:
    s = set(df.columns); return [c for c in cols if c in s]

def is_amount_col(colname: str) -> bool:
    lc = str(colname).lower()
    return any(k in lc for k in ["sum","total","—Å–∫–∏–¥–∫","—Å—É–º–º","—Ü–µ–Ω–∞","–¥–µ–ª—å—Ç–∞","usd"])

def add_totals_row_numeric(df: pd.DataFrame, label="–ò–¢–û–ì–û") -> pd.DataFrame:
    if df is None or df.empty: return df
    out = df.copy()
    num_cols = [c for c in out.columns if pd.api.types.is_numeric_dtype(out[c]) and is_amount_col(c)]
    if not num_cols: return out
    totals = {c: out[c].sum(skipna=True) for c in num_cols}
    label_col = next((c for c in ["plant_name","service_group","warranty_type","ticket_id","–ù–æ–º–µ—Ä –∑–∞—è–≤–∫–∏"] if c in out.columns), None)
    row = {c: "" for c in out.columns}; row.update(totals)
    if label_col: row[label_col] = label
    return pd.concat([out, pd.DataFrame([row])], ignore_index=True)

def format_numbers_ru(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty: return df
    out = df.copy()
    for c in out.columns:
        if c in EXCLUDE_NUM_FMT: continue
        if str(c).lower().endswith("id") or "id_" in str(c).lower(): continue
        if pd.api.types.is_numeric_dtype(out[c]):
            out[c] = out[c].apply(
                lambda x: f"{x:,.2f}".replace(",", "X").replace(".", ",").replace("X", " ")
                if pd.notnull(x) else ""
            )
    return out

def _col_to_excel(n: int) -> str:
    s=""; n+=1
    while n: n,r=divmod(n-1,26); s=chr(65+r)+s
    return s

def write_sheets_to_bytes(sheets: Dict[str, pd.DataFrame]) -> bytes:
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        wb = writer.book
        fmt_money = wb.add_format({'num_format': MONEY_FORMAT_RU})
        fmt_text  = wb.add_format({'num_format': '@'})
        fmt_bold  = wb.add_format({'bold': True})
        fmt_bold_money = wb.add_format({'bold': True, 'num_format': MONEY_FORMAT_RU})

        for name, dfw in sheets.items():
            dfw = dfw.copy()
            ensure_ticket_id_text_inplace(dfw)
            dfw.to_excel(writer, sheet_name=name, index=False)
            ws = writer.sheets[name]

            money_idx = []
            for i,c in enumerate(dfw.columns):
                if is_amount_col(c) and pd.api.types.is_numeric_dtype(dfw[c]):
                    money_idx.append(i)

            # base widths + formats
            for i,c in enumerate(dfw.columns):
                if c in ("ticket_id","–ù–æ–º–µ—Ä –∑–∞—è–≤–∫–∏"):
                    ws.set_column(i, i, 18, fmt_text)
                elif i in money_idx:
                    ws.set_column(i, i, 16, fmt_money)
                else:
                    ws.set_column(i, i, 12)

            # simple autofit
            for i,c in enumerate(dfw.columns):
                vals = dfw.iloc[:, i].astype(str).head(200).tolist()
                width = min(max(10, max(len(str(c)), *(len(v) for v in vals)) + 2), 42)
                keep = fmt_text if c in ("ticket_id","–ù–æ–º–µ—Ä –∑–∞—è–≤–∫–∏") else (fmt_money if i in money_idx else None)
                ws.set_column(i, i, width, keep)

            # totals row
            nrows = len(dfw)
            if nrows > 0 and money_idx:
                tr = nrows + 1
                label_col = next((j for j in range(len(dfw.columns)) if j not in money_idx), 0)
                ws.write(tr, label_col, "–ò–¢–û–ì–û", fmt_bold)
                for j in money_idx:
                    col = _col_to_excel(j)
                    ws.write_formula(tr, j, f"=SUM({col}2:{col}{nrows+1})", fmt_bold_money)

    output.seek(0)
    return output.getvalue()

# ---------- Data config ----------
@dataclass
class PipelineConfig:
    src_sheet: str = "–î–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π"
    excluded_for_manufacturer: Tuple[str, ...] = ("–í–´–ó–û–í", "–ü–†–û–î–ê–ñ–ê")
    spare_parts_labels: Tuple[str, ...] = ("–ó–∞–ø—á–∞—Å—Ç—å", )
    ml_threshold: float = 0.85
    rename_map: Dict[str, str] = field(default_factory=lambda: {
        "–ù–æ–º–µ—Ä –∑–∞—è–≤–∫–∏": "ticket_id",
        "–¢–∏–ø –≥–∞—Ä–∞–Ω—Ç–∏–∏": "warranty_type",
        "–ì—Ä—É–ø–ø–∞ —É—Å–ª—É–≥": "service_group",
        "–ì—Ä—É–ø–ø–∞ —É—Å–ª—É–≥ ": "service_group",
        "–£—Å–ª—É–≥–∞": "service_name",
        "–°—É–º–º–∞ –ø–æ –ø—Ä–æ–¥—É–∫—Ç—É": "sum_product",
        "–°—É–º–º–∞ –ø–æ —É—Å–ª—É–≥–µ": "sum_service",
        "–°—É–º–º–∞ –ø–æ –ø—Ä–æ–¥—É–∫—Ç—É –ë–µ–∑ —Å–∫–∏–¥–∫–∏": "sum_product_before_disc",
        "–°—É–º–º–∞ –ø–æ —É—Å–ª—É–≥–µ –ë–µ–∑ —Å–∫–∏–¥–∫–∏": "sum_service_before_disc",
        "–°–∫–∏–¥–∫–∞ –Ω–∞ —É—Å–ª—É–≥—É": "discount_service",
        "–°–∫–∏–¥–∫–∞ –Ω–∞ –ø—Ä–æ–¥—É–∫—Ç": "discount_product",
        "–∑–∞–≤–æ–¥": "plant_name",
        "–í–∏–¥ –º–∞—Ç–µ—Ä–∏–∞–ª–∞": "material_type",
        "–í–∏–¥ –º–∞—Ç–µ—Ä–∏–∞–ª–∞ ": "material_type",
        "–ë—Ä–µ–Ω–¥": "brand",
        "–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è": "created_at",
        "–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏": "sold_at",
        "–°–µ—Ä–≤–∏—Å–Ω—ã–π —Ü–µ–Ω—Ç—Ä": "service_center",
        "–°–µ—Ä–≤–∏—Å–Ω—ã–π —Ü–µ–Ω—Ç—Ä ": "service_center",
        "–ö–æ–¥ –ø—Ä–æ–¥—É–∫—Ç–∞": "product_code",
        "–ü—Ä–æ–¥—É–∫—Ç": "product_name",
        "–¢–∏–ø –∑–∞—è–≤–∫–∏": "request_type",
        "–°—Ç–∞—Ç—É—Å –∑–∞—è–≤–∫–∏": "ticket_status",
        "–°—Ç–∞—Ç—É—Å –∑–∞—è–≤–∫–∏ ": "ticket_status",
        "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ": "tech_conclusion",
        "–°–ü–° 1": "sps1",
        "–°–ü–° 2": "sps2",
        "–¥–∞—Ç–∞ —Å–ø—Å": "sps_date",
        "–ö–æ–¥ —É—Å–ª—É–≥–∏": "service_code",
        "–°—Ç–æ–∏–º–æ—Å—Ç—å —É—Å–ª—É–≥–∏": "service_unit_price",
        "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Å–ª—É–≥": "qty_service",
        "–î–∞—Ç–∞ –æ–∫–∞–∑–∞–Ω–∏—è": "service_date",
        "–î–∞—Ç–∞ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è": "post_date",
    })
    required_cols: Tuple[str, ...] = (
        "ticket_id","warranty_type","service_group","sum_product","sum_service",
        "discount_service","discount_product","plant_name","material_type",
        "service_code","service_unit_price","qty_service","sps_date"
    )

# ---------- Sidebar (inputs) ----------
st.sidebar.header("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ")
uploaded = st.sidebar.file_uploader("Excel –∏–∑ CRM (.xlsx)", type=["xlsx"])
sheet_name = st.sidebar.text_input("–ò–º—è –ª–∏—Å—Ç–∞", value="–î–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π")

st.sidebar.markdown("---")
st.sidebar.header("–ö—É—Ä—Å—ã –≤–∞–ª—é—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)")
rates_file = st.sidebar.file_uploader("–ö—É—Ä—Å UZS‚ÜíUSD (CSV/XLSX)", type=["csv","xlsx"])

st.sidebar.markdown("---")
apply_filters_to_export = st.sidebar.checkbox("–ü—Ä–∏–º–µ–Ω–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä—ã –∫ Excel-–≤—ã–≥—Ä—É–∑–∫–µ", value=True)

# ---------- Cached I/O ----------
@st.cache_data(show_spinner=False)
def read_excel_cached(file_bytes: bytes, sheet: str) -> pd.DataFrame:
    return pd.read_excel(io.BytesIO(file_bytes), sheet_name=sheet)

@st.cache_data(show_spinner=False)
def read_rates(file) -> pd.DataFrame:
    df = pd.read_csv(file) if file.name.lower().endswith(".csv") else pd.read_excel(file)
    cols = {c.strip().lower(): c for c in df.columns}
    date_col = next((cols[k] for k in cols if k in ("date","–¥–∞—Ç–∞")), None)
    rate_col = next((cols[k] for k in cols if k in ("rate","–∫—É—Ä—Å","uzs_usd","uzs_to_usd")), None)
    if not date_col or not rate_col:
        raise ValueError("–ù—É–∂–Ω—ã –∫–æ–ª–æ–Ω–∫–∏ 'date/–î–∞—Ç–∞' –∏ 'rate/–ö—É—Ä—Å'.")
    df = df.rename(columns={date_col:"date", rate_col:"rate"})
    df["date"] = pd.to_datetime(df["date"], errors="coerce")
    df["rate"] = pd.to_numeric(df["rate"], errors="coerce")
    return df.dropna(subset=["date","rate"]).sort_values("date").drop_duplicates("date", keep="last")[["date","rate"]]

# ---------- Pipeline functions ----------
def load_and_normalize(file_bytes: bytes, cfg: PipelineConfig, sheet: Optional[str]) -> pd.DataFrame:
    df = read_excel_cached(file_bytes, sheet or cfg.src_sheet)
    df.columns = [c.strip() for c in df.columns]
    df = df.rename(columns={k:v for k,v in cfg.rename_map.items() if k in df.columns})
    df = coalesce_duplicate_columns(df)

    for col in cfg.required_cols:
        if col not in df.columns: df[col] = np.nan

    num_cols = ["sum_product","sum_service","discount_service","discount_product","service_unit_price","qty_service"]
    for c in num_cols: df[c] = pd.to_numeric(df[c], errors="coerce")
    df["qty_service"] = df["qty_service"].fillna(1)
    df[num_cols[:-1]] = df[num_cols[:-1]].fillna(0)  # –≤—Å–µ –∫—Ä–æ–º–µ qty

    # dates
    for d in ["sps_date","service_date","post_date","sold_at","created_at"]:
        if d in df.columns: df[d] = pd.to_datetime(df[d], errors="coerce")

    df["service_group_up"] = df["service_group"].astype(str).str.upper().str.strip()
    df["warranty_type"] = df["warranty_type"].astype(str).str.upper().str.strip()
    df["material_type"] = df["material_type"].astype(str).str.strip()

    df["sum_total"] = df["sum_product"] + df["sum_service"]
    df["discount_total"] = df["discount_service"] + df["discount_product"]

    ensure_ticket_id_text_inplace(df)
    return df

def apply_usd_conversion(df: pd.DataFrame, rates: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    wd = out["sps_date"]
    if wd.isna().all():
        for f in ["service_date","post_date","sold_at","created_at"]:
            if f in out.columns:
                tmp = pd.to_datetime(out[f], errors="coerce")
                if tmp.notna().any():
                    wd = tmp; break
    out["_rate_date"] = pd.to_datetime(wd, errors="coerce")
    tmp = out[["_rate_date"]].copy()
    tmp["__row__"] = np.arange(len(tmp))
    tmp = tmp.sort_values("_rate_date")
    r = rates.sort_values("date")
    merged = pd.merge_asof(tmp, r, left_on="_rate_date", right_on="date", direction="backward").sort_values("__row__")
    out["usd_rate"] = merged["rate"].values
    for c in ["sum_product","sum_service","sum_total","discount_product","discount_service","discount_total"]:
        if c in out.columns:
            out[c+"_usd"] = np.where(out["usd_rate"] > 0, out[c] / out["usd_rate"], np.nan)
    return out

# ---------- FILTERS (full) ----------
def build_filters(df: pd.DataFrame):
    """Render filters and return filtered DataFrame."""
    d = df.copy()

    st.subheader("–§–∏–ª—å—Ç—Ä—ã")

    r1c1, r1c2, r1c3, r1c4 = st.columns(4)
    with r1c1:
        plants = ["(–≤—Å–µ)"] + sorted(d.get("plant_name", pd.Series([], dtype=str)).dropna().astype(str).unique().tolist())
        plant_sel = st.selectbox("–ó–∞–≤–æ–¥", plants, index=0)
        if plant_sel != "(–≤—Å–µ)":
            d = d[d["plant_name"] == plant_sel]

    with r1c2:
        brands = ["(–≤—Å–µ)"] + sorted(d.get("brand", pd.Series([], dtype=str)).dropna().astype(str).unique().tolist())
        brand_sel = st.selectbox("–ë—Ä–µ–Ω–¥", brands, index=0)
        if brand_sel != "(–≤—Å–µ)" and "brand" in d.columns:
            d = d[d["brand"] == brand_sel]

    with r1c3:
        warranties = ["(–≤—Å–µ)", "G1", "G2", "G3"]
        w_sel = st.selectbox("–ì–∞—Ä–∞–Ω—Ç–∏—è", warranties, index=0)
        if w_sel != "(–≤—Å–µ)":
            d = d[d["warranty_type"] == w_sel]

    with r1c4:
        mind, maxd = pd.to_datetime(d["sps_date"]).min(), pd.to_datetime(d["sps_date"]).max()
        if pd.notna(mind) and pd.notna(maxd):
            start, end = st.date_input("–ü–µ—Ä–∏–æ–¥ –ø–æ '–¥–∞—Ç–∞ —Å–ø—Å'", value=(mind.date(), maxd.date()))
            if start and end:
                mask = (pd.to_datetime(d["sps_date"]).dt.date >= start) & (pd.to_datetime(d["sps_date"]).dt.date <= end)
                d = d[mask]

    r2c1, r2c2, r2c3, r2c4 = st.columns(4)
    with r2c1:
        all_groups = sorted(d.get("service_group", pd.Series([], dtype=str)).dropna().astype(str).unique().tolist())
        sel_groups = st.multiselect("–ì—Ä—É–ø–ø—ã —É—Å–ª—É–≥", all_groups, default=all_groups[:10] if len(all_groups)>10 else all_groups)
        if sel_groups:
            d = d[d["service_group"].astype(str).isin(sel_groups)]

    with r2c2:
        part_mode = st.select_slider("–ó–∞–ø—á–∞—Å—Ç–∏", options=["–í—Å–µ", "–¢–æ–ª—å–∫–æ –∑–∞–ø—á–∞—Å—Ç–∏", "–ò—Å–∫–ª—é—á–∏—Ç—å –∑–∞–ø—á–∞—Å—Ç–∏"], value="–í—Å–µ")
        if "is_spare_part" in d.columns:
            if part_mode == "–¢–æ–ª—å–∫–æ –∑–∞–ø—á–∞—Å—Ç–∏":
                d = d[d["is_spare_part"] == True]
            elif part_mode == "–ò—Å–∫–ª—é—á–∏—Ç—å –∑–∞–ø—á–∞—Å—Ç–∏":
                d = d[d["is_spare_part"] == False]

    with r2c3:
        min_sum, max_sum = float(d["sum_total"].min() or 0), float(d["sum_total"].max() or 0)
        min_v, max_v = st.slider("–û–±–æ—Ä–æ—Ç (UZS), –¥–∏–∞–ø–∞–∑–æ–Ω", min_value=0.0, max_value=max(1.0, max_sum), value=(0.0, max_sum))
        d = d[(d["sum_total"] >= min_v) & (d["sum_total"] <= max_v)]

    with r2c4:
        min_disc, max_disc = float(d["discount_total"].min() or 0), float(d["discount_total"].max() or 0)
        min_dv, max_dv = st.slider("–°–∫–∏–¥–∫–∞ (UZS), –¥–∏–∞–ø–∞–∑–æ–Ω", min_value=min(0.0, min_disc), max_value=max(1.0, max_disc), value=(min(0.0, min_disc), max_disc))
        d = d[(d["discount_total"] >= min_dv) & (d["discount_total"] <= max_dv)]

    r3c1, r3c2 = st.columns([2,2])
    with r3c1:
        search_text = st.text_input("–ü–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç—É (–∫–æ–¥/—É—Å–ª—É–≥–∞/–ø—Ä–æ–¥—É–∫—Ç/–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π)", value="")
        if search_text.strip():
            patt = search_text.strip().lower()
            search_cols = existing_cols(d, ["service_name","service_group","product_name","product_code","service_code","ticket_id","sps1","sps2"])
            if search_cols:
                mask = False
                for c in search_cols:
                    mask = mask | d[c].astype(str).str.lower().str.contains(patt, na=False)
                d = d[mask]

    with r3c2:
        only_g12_for_ar = st.checkbox("–ò—Å–∫–ª—é—á–∏—Ç—å –∏–∑ –∑–∞—Ç—Ä–∞—Ç –∑–∞–≤–æ–¥–∞ (–í–´–ó–û–í/–ü–†–û–î–ê–ñ–ê)", value=False)
        if only_g12_for_ar and "service_group_up" in d.columns:
            d = d[~d["service_group_up"].isin(["–í–´–ó–û–í","–ü–†–û–î–ê–ñ–ê"])]

    return d

# ---------- Aggregations ----------
def aggregate_by_ticket(df: pd.DataFrame, use_usd=False) -> pd.DataFrame:
    if use_usd:
        return (df.groupby("ticket_id").agg(
            sum_product=("sum_product_usd","sum"),
            sum_service=("sum_service_usd","sum"),
            sum_total=("sum_total_usd","sum"),
            discount_product=("discount_product_usd","sum"),
            discount_service=("discount_service_usd","sum"),
            discount_total=("discount_total_usd","sum"),
            warranty_type=("warranty_type","first"),
            plant_name=("plant_name","first")
        ).reset_index())
    return (df.groupby("ticket_id").agg(
        sum_product=("sum_product","sum"),
        sum_service=("sum_service","sum"),
        sum_total=("sum_total","sum"),
        discount_product=("discount_product","sum"),
        discount_service=("discount_service","sum"),
        discount_total=("discount_total","sum"),
        warranty_type=("warranty_type","first"),
        plant_name=("plant_name","first")
    ).reset_index())

def warranty_totals_from_id(agg_id: pd.DataFrame) -> pd.DataFrame:
    return (agg_id.groupby("warranty_type")[["sum_product","sum_service","sum_total","discount_total"]].sum().reset_index())

def ar_by_plant(df: pd.DataFrame, use_usd=False) -> tuple[pd.DataFrame, pd.DataFrame]:
    mask = df["warranty_type"].isin(["G1","G2"]) & (~df.get("is_excluded_for_manufacturer", False).fillna(False))
    cols = ["plant_name","warranty_type","ticket_id"]
    vals = ["sum_product_usd","sum_service_usd","sum_total_usd","discount_total_usd"] if use_usd else \
           ["sum_product","sum_service","sum_total","discount_total"]
    ar_lines = df.loc[mask, cols + vals]
    ar_id = (ar_lines.groupby(["plant_name","warranty_type","ticket_id"], as_index=False)
             .agg(**{vals[0]:(vals[0],"sum"), vals[1]:(vals[1],"sum"), vals[2]:(vals[2],"sum"), vals[3]:(vals[3],"sum")}))
    ar_summary = (ar_id.groupby(["plant_name","warranty_type"], as_index=False)
                  .agg(**{vals[0]:(vals[0],"sum"), vals[1]:(vals[1],"sum"), vals[2]:(vals[2],"sum"), vals[3]:(vals[3],"sum")})
                  .sort_values(vals[2], ascending=False))
    return ar_id, ar_summary

def g3_views(df: pd.DataFrame, use_usd=False) -> tuple[pd.DataFrame, pd.DataFrame]:
    base = ["service_group","ticket_id","is_spare_part","plant_name"]
    vals = ["sum_product_usd","sum_service_usd","sum_total_usd","discount_total_usd"] if use_usd else \
           ["sum_product","sum_service","sum_total","discount_total"]
    g3_lines = df.loc[df["warranty_type"]=="G3", base+vals].copy()
    g3_summary = (g3_lines.groupby("service_group", as_index=False)
                  .agg(**{vals[0]:(vals[0],"sum"), vals[1]:(vals[1],"sum"), vals[2]:(vals[2],"sum"), vals[3]:(vals[3],"sum")})
                  .sort_values(vals[2], ascending=False))
    return g3_lines, g3_summary

def dblock_outputs(df: pd.DataFrame, use_usd=False) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    mask_pay = df["is_spare_part"] & df["warranty_type"].isin(["G2","G3"])
    base = existing_cols(df, ["plant_name","warranty_type","ticket_id","product_name","product_code"])
    if use_usd:
        vals = existing_cols(df, ["sum_product_usd","discount_product_usd"])
        pay_lines = df.loc[mask_pay, base+vals].copy().rename(columns={
            "sum_product_usd":"sum_product","discount_product_usd":"discount_product"
        })
    else:
        vals = existing_cols(df, ["sum_product","discount_product"])
        pay_lines = df.loc[mask_pay, base+vals].copy()
    pay_summary = (pay_lines.groupby(existing_cols(pay_lines, ["plant_name","warranty_type"]), as_index=False)
                   .agg(–°—É–º–º–∞_–∑–∞–ø—á–∞—Å—Ç–µ–π=("sum_product","sum"),
                        –°–∫–∏–¥–∫–∏_–ø–æ_–∑–∞–ø—á–∞—Å—Ç—è–º_–∏–Ω—Ñ–æ=("discount_product","sum"))
                   .sort_values("–°—É–º–º–∞_–∑–∞–ø—á–∞—Å—Ç–µ–π", ascending=False, na_position="last"))
    mask_disc = df["is_spare_part"] & (
        (df.get("discount_product",0)>0)|(df.get("discount_service",0)>0)|
        (df.get("discount_product_usd",0)>0)|(df.get("discount_service_usd",0)>0)
    )
    base_d = existing_cols(df, ["plant_name","warranty_type","ticket_id","product_name","product_code"])
    if use_usd:
        vals_d = existing_cols(df, ["discount_product_usd","discount_service_usd","sum_product_usd","sum_service_usd","sum_total_usd"])
        disc = df.loc[mask_disc, base_d+vals_d].copy().rename(columns={
            "discount_product_usd":"discount_product","discount_service_usd":"discount_service",
            "sum_product_usd":"sum_product","sum_service_usd":"sum_service","sum_total_usd":"sum_total"
        })
    else:
        vals_d = existing_cols(df, ["discount_product","discount_service","sum_product","sum_service","sum_total"])
        disc = df.loc[mask_disc, base_d+vals_d].copy()
    return pay_lines, pay_summary, disc

# ---------- MAIN ----------
cfg = PipelineConfig(src_sheet=sheet_name)

if uploaded is None:
    st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel-—Ñ–∞–π–ª CRM (.xlsx) –≤ —Å–∞–π–¥–±–∞—Ä–µ.")
    st.stop()

try:
    with st.spinner("–ß—Ç–µ–Ω–∏–µ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è..."):
        df = load_and_normalize(uploaded.getvalue(), cfg, sheet_name)

    # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ ‚Äî –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ USD
    usd_enabled = False
    if rates_file is not None:
        with st.spinner("–ü—Ä–∏–º–µ–Ω—è–µ–º –∫—É—Ä—Å UZS‚ÜíUSD..."):
            rates = read_rates(rates_file)
            df = apply_usd_conversion(df, rates)
            usd_enabled = True

    # --------- –§–ò–õ–¨–¢–†–´ ---------
    df_view = build_filters(df)

    # --------- KPI ---------
    st.success("–ì–æ—Ç–æ–≤–æ! –ù–∏–∂–µ –¥–∞—à–±–æ—Ä–¥, —Å–≤–æ–¥—ã –∏ –≤—ã–≥—Ä—É–∑–∫–∞.")
    st.markdown("### üìä –ö–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ (–ø–æ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º)")
    k1,k2,k3,k4 = st.columns(4)
    ssum = lambda d,c: float(pd.to_numeric(d.get(c, pd.Series(dtype=float)), errors="coerce").sum())
    k1.metric("–ò—Ç–æ–≥–æ –æ–±–æ—Ä–æ—Ç (UZS)", f"{ssum(df_view,'sum_total'):,.2f}".replace(",", "X").replace(".", ",").replace("X", " "))
    k2.metric("–°–∫–∏–¥–∫–∏ (UZS)", f"{ssum(df_view,'discount_total'):,.2f}".replace(",", "X").replace(".", ",").replace("X", " "))
    k3.metric("–£—Å–ª—É–≥–∏ (UZS)", f"{ssum(df_view,'sum_service'):,.2f}".replace(",", "X").replace(".", ",").replace("X", " "))
    k4.metric("–ú–∞—Ç–µ—Ä–∏–∞–ª—ã (UZS)", f"{ssum(df_view,'sum_product'):,.2f}".replace(",", "X").replace(".", ",").replace("X", " "))
    if usd_enabled and "sum_total_usd" in df_view.columns:
        k5,k6,k7,k8 = st.columns(4)
        k5.metric("–û–±–æ—Ä–æ—Ç (USD)", f"{ssum(df_view,'sum_total_usd'):,.2f}")
        k6.metric("–°–∫–∏–¥–∫–∏ (USD)", f"{ssum(df_view,'discount_total_usd'):,.2f}")
        k7.metric("–£—Å–ª—É–≥–∏ (USD)", f"{ssum(df_view,'sum_service_usd'):,.2f}")
        k8.metric("–ú–∞—Ç–µ—Ä–∏–∞–ª—ã (USD)", f"{ssum(df_view,'sum_product_usd'):,.2f}")

    # --------- –ì—Ä–∞—Ñ–∏–∫–∏ ---------
    st.markdown("### üìà –ì—Ä–∞—Ñ–∏–∫–∏")
    if ALTAIR_OK:
        cc1, cc2 = st.columns(2)
        with cc1:
            top_plants = (df_view.groupby("plant_name", as_index=False)["sum_total"].sum()
                          .sort_values("sum_total", ascending=False).head(10))
            if not top_plants.empty:
                st.altair_chart(
                    alt.Chart(top_plants).mark_bar().encode(
                        x=alt.X("sum_total:Q", title="–û–±–æ—Ä–æ—Ç (UZS)"),
                        y=alt.Y("plant_name:N", sort='-x', title="–ó–∞–≤–æ–¥"),
                        tooltip=["plant_name","sum_total"]
                    ).properties(height=320),
                    use_container_width=True
                )
        with cc2:
            g3_grp = (df_view[df_view["warranty_type"]=="G3"]
                      .groupby("service_group",as_index=False)["sum_total"].sum()
                      .sort_values("sum_total", ascending=False).head(10))
            if not g3_grp.empty:
                st.altair_chart(
                    alt.Chart(g3_grp).mark_bar().encode(
                        x=alt.X("sum_total:Q", title="G3 –æ–±–æ—Ä–æ—Ç (UZS)"),
                        y=alt.Y("service_group:N", sort='-x', title="–ì—Ä—É–ø–ø–∞ —É—Å–ª—É–≥"),
                        tooltip=["service_group","sum_total"]
                    ).properties(height=320),
                    use_container_width=True
                )
    else:
        st.info("Altair –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –≥—Ä–∞—Ñ–∏–∫–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã.")

    # --------- –°–≤–æ–¥—ã/—Ç–∞–±–ª–∏—Ü—ã ---------
    with st.spinner("–°—Ç—Ä–æ–∏–º —Å–≤–æ–¥—ã..."):
        agg_id = aggregate_by_ticket(df_view, use_usd=False)
        warranty_totals = warranty_totals_from_id(agg_id)
        ar_id, ar_summary = ar_by_plant(df_view, use_usd=False)
        g3_lines, g3_summary = g3_views(df_view, use_usd=False)
        dblock_pay_lines, dblock_pay_summary, dblock_disc_register = dblock_outputs(df_view, use_usd=False)

        if usd_enabled:
            agg_id_usd = aggregate_by_ticket(df_view, use_usd=True)
            warranty_totals_usd = warranty_totals_from_id(agg_id_usd)
            ar_id_usd, ar_summary_usd = ar_by_plant(df_view, use_usd=True)
            g3_lines_usd, g3_summary_usd = g3_views(df_view, use_usd=True)
            dblock_pay_lines_usd, dblock_pay_summary_usd, dblock_disc_register_usd = dblock_outputs(df_view, use_usd=True)
        else:
            warranty_totals_usd = ar_summary_usd = g3_summary_usd = None

    c1,c2 = st.columns(2)
    with c1:
        st.subheader("–ò—Ç–æ–≥–∏ –ø–æ –≥–∞—Ä–∞–Ω—Ç–∏–∏ (UZS)")
        st.dataframe(format_numbers_ru(add_totals_row_numeric(warranty_totals).head(200)))
        st.subheader("AR –ø–æ –∑–∞–≤–æ–¥–∞–º ‚Äî —Å–≤–æ–¥ (UZS)")
        st.dataframe(format_numbers_ru(add_totals_row_numeric(ar_summary).head(200)))
        if usd_enabled and warranty_totals_usd is not None:
            st.subheader("–ò—Ç–æ–≥–∏ –ø–æ –≥–∞—Ä–∞–Ω—Ç–∏–∏ (USD)")
            st.dataframe(format_numbers_ru(add_totals_row_numeric(warranty_totals_usd).head(200)))
            st.subheader("AR –ø–æ –∑–∞–≤–æ–¥–∞–º ‚Äî —Å–≤–æ–¥ (USD)")
            st.dataframe(format_numbers_ru(add_totals_row_numeric(ar_summary_usd).head(200)))
    with c2:
        st.subheader("G3 ‚Äî —Å–≤–æ–¥ (UZS)")
        st.dataframe(format_numbers_ru(add_totals_row_numeric(g3_summary).head(200)))
        if usd_enabled and g3_summary_usd is not None:
            st.subheader("G3 ‚Äî —Å–≤–æ–¥ (USD)")
            st.dataframe(format_numbers_ru(add_totals_row_numeric(g3_summary_usd).head(200)))
        st.subheader("–î-–ë–ª–æ–∫ ‚Äî —Å–≤–æ–¥")
        st.dataframe(format_numbers_ru(add_totals_row_numeric(dblock_pay_summary).head(200)))

    # --------- Export ---------
    st.markdown("---")
    st.subheader("–≠–∫—Å–ø–æ—Ä—Ç –≤ Excel")
    base = df_view if apply_filters_to_export else df
    # –ø–µ—Ä–µ—Å—á—ë—Ç —Å–≤–æ–¥–æ–≤ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ (–∏–∑ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –±–∞–∑—ã)
    agg_id_e = aggregate_by_ticket(base, use_usd=False)
    warranty_totals_e = warranty_totals_from_id(agg_id_e)
    ar_id_e, ar_summary_e = ar_by_plant(base, use_usd=False)
    g3_lines_e, g3_summary_e = g3_views(base, use_usd=False)
    dblock_pay_lines_e, dblock_pay_summary_e, dblock_disc_register_e = dblock_outputs(base, use_usd=False)

    sheets = {
        "–ò—Ç–æ–≥–∏_–ø–æ_ID": agg_id_e,
        "–ò—Ç–æ–≥–∏_–ø–æ_–ì–∞—Ä–∞–Ω—Ç–∏–∏": warranty_totals_e,
        "–ê–†_–ø–æ_–ó–∞–≤–æ–¥–∞–º_ID": ar_id_e,
        "–ê–†_–ø–æ_–ó–∞–≤–æ–¥–∞–º_–°–≤–æ–¥": ar_summary_e,
        "–ì3_–°—Ç—Ä–æ–∫–∏": g3_lines_e,
        "–ì3_–°–≤–æ–¥": g3_summary_e,
        "–î–ë–ª–æ–∫_–ö—Ä–µ–¥–∏—Ç–æ—Ä–∫–∞_–°—Ç—Ä–æ–∫–∏": dblock_pay_lines_e,
        "–î–ë–ª–æ–∫_–ö—Ä–µ–¥–∏—Ç–æ—Ä–∫–∞_–°–≤–æ–¥": dblock_pay_summary_e,
        "–î–ë–ª–æ–∫_–°–∫–∏–¥–∫–∏": dblock_disc_register_e,
    }
    if usd_enabled and "sum_total_usd" in base.columns:
        agg_id_ue = aggregate_by_ticket(base, use_usd=True)
        warranty_totals_ue = warranty_totals_from_id(agg_id_ue)
        ar_id_ue, ar_summary_ue = ar_by_plant(base, use_usd=True)
        g3_lines_ue, g3_summary_ue = g3_views(base, use_usd=True)
        dblock_pay_lines_ue, dblock_pay_summary_ue, dblock_disc_register_ue = dblock_outputs(base, use_usd=True)
        sheets.update({
            "–ò—Ç–æ–≥–∏_–ø–æ_ID_USD": agg_id_ue,
            "–ò—Ç–æ–≥–∏_–ø–æ_–ì–∞—Ä–∞–Ω—Ç–∏–∏_USD": warranty_totals_ue,
            "–ê–†_–ø–æ_–ó–∞–≤–æ–¥–∞–º_ID_USD": ar_id_ue,
            "–ê–†_–ø–æ_–ó–∞–≤–æ–¥–∞–º_–°–≤–æ–¥_USD": ar_summary_ue,
            "–ì3_–°—Ç—Ä–æ–∫–∏_USD": g3_lines_ue,
            "–ì3_–°–≤–æ–¥_USD": g3_summary_ue,
            "–î–ë–ª–æ–∫_–ö—Ä–µ–¥–∏—Ç–æ—Ä–∫–∞_–°—Ç—Ä–æ–∫–∏_USD": dblock_pay_lines_ue,
            "–î–ë–ª–æ–∫_–ö—Ä–µ–¥–∏—Ç–æ—Ä–∫–∞_–°–≤–æ–¥_USD": dblock_pay_summary_ue,
            "–î–ë–ª–æ–∫_–°–∫–∏–¥–∫–∏_USD": dblock_disc_register_ue,
        })

    xlsx = write_sheets_to_bytes(sheets)
    st.download_button(
        label="üíæ –°–∫–∞—á–∞—Ç—å Excel",
        data=xlsx,
        file_name="–§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ_–∏—Ç–æ–≥–∏_–º–µ—Å—è—Ü–∞.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

except Exception as e:
    st.error(f"–û—à–∏–±–∫–∞: {e}")
